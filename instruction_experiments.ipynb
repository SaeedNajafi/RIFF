{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Description\n",
    "\n",
    "<p> In this set of experiments, we are going to test the manual templates on various text classification tasks. We are going to use a fixed backbone roberta-large language model.\n",
    "\n",
    "<p> With manual templates, we no longer need any training examples and we will only make predictions on the corresponding test sets.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 on SST-2 Sentiment\n",
    "\n",
    "In the first Experiment, we are going to make predictions on the SST-2 binary sentiment classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"~/template_experiments\"\n",
    "!mkdir -p \"~/template_experiments/sst2\"\n",
    "!mkdir -p \"~/template_experiments/sst2/with_instruction/\"\n",
    "!mkdir -p \"~/template_experiments/sst2/no_instruction/\"\n",
    "!mkdir -p \"~/template_experiments/sst2/with_instruction_data_aug/\"\n",
    "!mkdir -p \"~/template_experiments/sst2/no_instruction_data_aug/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run our prediction script with the required arguments for the no template experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0512 15:11:41.482063 139898591756416 builder.py:798] Found cached dataset sst2 (/h/snajafi/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "W0512 15:11:41.507922 139898591756416 arrow_dataset.py:2942] Loading cached processed dataset at /h/snajafi/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-c01b3b30d2e0d379.arrow\n",
      "2023-05-12 15:11:46.633409: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-12 15:11:46.633690: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-05-12 15:11:46.633974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-12 15:11:46.634194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-05-12 15:11:46.634242: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Predicting...\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/pkgs/python-3.9.10/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/pkgs/python-3.9.10/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/trainer.py\", line 367, in <module>\n",
      "    app.run(main)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/trainer.py\", line 361, in main\n",
      "    launch_no_finetune_predict()\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/trainer.py\", line 179, in launch_no_finetune_predict\n",
      "    test_model(\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/trainer.py\", line 146, in test_model\n",
      "    start_predicting(model, test_dataloader, FLAGS.prediction_file)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/trainer.py\", line 49, in start_predicting\n",
      "    for ret_row in model.predict(batch):\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/prompted_lm.py\", line 608, in paraphrase_and_predict\n",
      "    paraphrases, _ = self.para_model.generate_top_p_paraphrases(batch, num_return_seq=FLAGS.beam_size)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/prompted_lm.py\", line 315, in generate_top_p_paraphrases\n",
      "    predictions_output = bart_model.generate(\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/generation/utils.py\", line 1452, in generate\n",
      "    return self.sample(\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/generation/utils.py\", line 2481, in sample\n",
      "    next_token_scores = logits_processor(input_ids, next_token_logits)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/generation/logits_process.py\", line 92, in __call__\n",
      "    scores = processor(input_ids, scores)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/generation/logits_process.py\", line 492, in __call__\n",
      "    banned_batch_tokens = _calc_banned_ngram_tokens(self.ngram_size, input_ids, num_batch_hypotheses, cur_len)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/generation/logits_process.py\", line 465, in _calc_banned_ngram_tokens\n",
      "    generated_ngrams = _get_ngrams(ngram_size, prev_input_ids, num_hypos)\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/generation/logits_process.py\", line 445, in _get_ngrams\n",
      "    prev_ngram_tuple = tuple(ngram[:-1])\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m src.reference_implementations.prompt_zoo.trainer \\\n",
    "    --eval_batch_size 4 \\\n",
    "    --task_name sst2 \\\n",
    "    --exp_type no_finetune \\\n",
    "    --source_max_length 128 \\\n",
    "    --decoder_max_length 128 \\\n",
    "    --test_file validation \\\n",
    "    --model_path ~/template_experiments/sst2/with_instruction/ \\\n",
    "    --prediction_file ~/template_experiments/sst2/with_instruction/sst2.validation.with_instruction.predictions.csv \\\n",
    "    --instruction_type manual_template_research_sst2_with_instruction \\\n",
    "    --pretrained_model roberta-large \\\n",
    "    --enable_data_augmentation 1 \\\n",
    "    --enable_paraphrase_training 0 \\\n",
    "    --load_paraphraser 0 \\\n",
    "    --beam_size 100 \\\n",
    "    --ensemble_type paraphrase_predict \\\n",
    "    --temperature 1.5 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/pkgs/python-3.9.10/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/pkgs/python-3.9.10/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/trainer.py\", line 367, in <module>\r\n",
      "    app.run(main)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/absl/app.py\", line 308, in run\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/absl/app.py\", line 254, in _run_main\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/trainer.py\", line 361, in main\r\n",
      "    launch_no_finetune_predict()\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/trainer.py\", line 159, in launch_no_finetune_predict\r\n",
      "    model = RobertaPrompted(\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/src/reference_implementations/prompt_zoo/prompted_lm.py\", line 376, in __init__\r\n",
      "    self.model_pool[\"roberta_model\"] = RobertaForMaskedLM.from_pretrained(FLAGS.pretrained_model)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 2498, in from_pretrained\r\n",
      "    model = cls(config, *model_args, **model_kwargs)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 1049, in __init__\r\n",
      "    self.roberta = RobertaModel(config, add_pooling_layer=False)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 722, in __init__\r\n",
      "    self.encoder = RobertaEncoder(config)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 475, in __init__\r\n",
      "    self.layer = nn.ModuleList([RobertaLayer(config) for _ in range(config.num_hidden_layers)])\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 475, in <listcomp>\r\n",
      "    self.layer = nn.ModuleList([RobertaLayer(config) for _ in range(config.num_hidden_layers)])\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 397, in __init__\r\n",
      "    self.output = RobertaOutput(config)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\", line 372, in __init__\r\n",
      "    self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 101, in __init__\r\n",
      "    self.reset_parameters()\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 107, in reset_parameters\r\n",
      "    init.kaiming_uniform_(self.weight, a=math.sqrt(5))\r\n",
      "  File \"/ssd003/home/snajafi/codes/PromptEngineering-research/prompt_torch-env/lib/python3.9/site-packages/torch/nn/init.py\", line 412, in kaiming_uniform_\r\n",
      "    return tensor.uniform_(-bound, bound)\r\n",
      "KeyboardInterrupt\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m src.reference_implementations.prompt_zoo.trainer \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --task_name sst2 \\\n",
    "    --exp_type no_finetune \\\n",
    "    --source_max_length 128 \\\n",
    "    --decoder_max_length 128 \\\n",
    "    --test_file validation \\\n",
    "    --model_path ~/template_experiments/sst2/with_instruction_data_aug/ \\\n",
    "    --prediction_file ~/template_experiments/sst2/with_instruction_data_aug/sst2.validation.with_instruction.predictions.csv \\\n",
    "    --instruction_type manual_template_research_sst2_with_instruction \\\n",
    "    --pretrained_model roberta-large \\\n",
    "    --enable_data_augmentation 1 \\\n",
    "    --enable_paraphrase_training 0 \\\n",
    "    --load_paraphraser 0 \\\n",
    "    --beam_size 8 \\\n",
    "    --ensemble_type paraphrase_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0425 13:54:48.890125 140291791294592 builder.py:798] Found cached dataset sst2 (/h/snajafi/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "W0425 13:54:48.897922 140291791294592 arrow_dataset.py:2942] Loading cached processed dataset at /h/snajafi/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-c01b3b30d2e0d379.arrow\n",
      "2023-04-25 13:54:50.777810: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-25 13:54:50.777918: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-25 13:54:50.777990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-25 13:54:50.778058: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-25 13:54:50.778094: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "!python -m src.reference_implementations.prompt_zoo.trainer \\\n",
    "    --eval_batch_size 128 \\\n",
    "    --task_name sst2 \\\n",
    "    --exp_type no_finetune \\\n",
    "    --source_max_length 128 \\\n",
    "    --decoder_max_length 128 \\\n",
    "    --test_file validation \\\n",
    "    --model_path ~/template_experiments/sst2/no_instruction/ \\\n",
    "    --prediction_file ~/template_experiments/sst2/no_instruction/sst2.validation.no_instruction.predictions.csv \\\n",
    "    --instruction_type manual_template_research_sst2_no_instruction \\\n",
    "    --pretrained_model roberta-large \\\n",
    "    --enable_data_augmentation 0 \\\n",
    "    --enable_paraphrase_training 0 \\\n",
    "    --load_paraphraser 0 \\\n",
    "    --beam_size 8 \\\n",
    "    --ensemble_type no_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0425 13:55:53.778370 139910046228608 builder.py:798] Found cached dataset sst2 (/h/snajafi/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "W0425 13:55:53.786235 139910046228608 arrow_dataset.py:2942] Loading cached processed dataset at /h/snajafi/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-c01b3b30d2e0d379.arrow\n",
      "2023-04-25 13:55:56.021824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-25 13:55:56.021931: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-25 13:55:56.022004: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-25 13:55:56.022075: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-25 13:55:56.022109: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "!python -m src.reference_implementations.prompt_zoo.trainer \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --task_name sst2 \\\n",
    "    --exp_type no_finetune \\\n",
    "    --source_max_length 128 \\\n",
    "    --decoder_max_length 128 \\\n",
    "    --test_file validation \\\n",
    "    --model_path ~/template_experiments/sst2/no_instruction_data_aug/ \\\n",
    "    --prediction_file ~/template_experiments/sst2/no_instruction_data_aug/sst2.validation.no_instruction.predictions.csv \\\n",
    "    --instruction_type manual_template_research_sst2_no_instruction \\\n",
    "    --pretrained_model roberta-large \\\n",
    "    --enable_data_augmentation 1 \\\n",
    "    --enable_paraphrase_training 0 \\\n",
    "    --load_paraphraser 0 \\\n",
    "    --beam_size 8 \\\n",
    "    --ensemble_type paraphrase_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
