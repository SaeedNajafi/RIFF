#!/bin/bash

#SBATCH --job-name=prompt-roberta-large
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=4
#SBATCH --gres=gpu:2
#SBATCH --mem=8G
#SBATCH --partition=a40
#SBATCH --qos=normal
#SBATCH --output=job_%x_%j.out
#SBATCH --error=job_%x_%j.err

# Note:
#	  ntasks: Total number of processes to use across world
#	  ntasks-per-node: How many processes each node should create
#		- If this is equal to the number of GPUs on the node, each GPU will run
#			a copy of the `srun ...` code
#		- `jax.distributed.initialize` requires that each GPU run a copy of the
#			code, in order to call initialize with no arguments

# Set location of host and access port
MAIN_HOST=$(hostname -s)
export MASTER_ADDR=$MAIN_HOST
export MASTER_PORT=52070

# Set NCCL options
# export NCCL_DEBUG=INFO
# NCCL backend to communicate between GPU workers is not provided in vector's cluster.
# Disable this option in slurm.
export NCCL_IB_DISABLE=1

if [[ "${SLURM_JOB_PARTITION}" == "t4v2" ]] || \
    [[ "${SLURM_JOB_PARTITION}" == "rtx6000" ]]; then
    echo export NCCL_SOCKET_IFNAME=bond0 on "${SLURM_JOB_PARTITION}"
    export NCCL_SOCKET_IFNAME=bond0
fi

# Process input args
SCRIPT=$1

LOG_DIR=$2

LOG_PATH="${LOG_DIR}/log_${SLURM_JOB_ID}_rank_\${SLURM_PROCID}.log"

EXP_TYPE=$3

TASK=$4

SEED=$5

MODEL_PATH=$6

# learning rate.
LR=$7

AUG=$8

TRAIN_PARA=$9

LOAD_PARA=${10}

LEN=${11}

PARA_LOSS=${12}

SAMPLING_METHOD=${13}

SAMPLING_ALG=${14}

echo "Placing logs in: ${LOG_DIR}"

echo "World size: ${SLURM_NTASKS}"
echo "Number of nodes: ${SLURM_NNODES}"
NUM_GPUs=$(nvidia-smi --query-gpu=name --format=csv,noheader | wc -l)
echo "GPUs per node: ${NUM_GPUs}"

# Make logging directories.
mkdir -p "${LOG_DIR}"

# Run on all nodes
/opt/slurm/bin/srun -N"${SLURM_NNODES}" -l \
    bash -c "bash ${SCRIPT} MAIN_PATH=${MODEL_PATH} \
             EXP_TYPE=${EXP_TYPE} LR=${LR} \
             SEED=${SEED} TASK=${TASK} LEN=${LEN} AUG=${AUG} \
             TRAIN_PARA=${TRAIN_PARA} LOAD_PARA=${LOAD_PARA} \
             PARA_LOSS=${PARA_LOSS} SAMPLING_METHOD=${SAMPLING_METHOD} \
             SAMPLING_ALG=${SAMPLING_ALG} SLURM_JOB_ID=${SLURM_JOB_ID} >> ${LOG_PATH} 2>&1"
